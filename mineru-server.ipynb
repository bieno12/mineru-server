{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f3a424",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#type: ignore\n",
    "!apt-get update\n",
    "!apt-get install -y \\\n",
    "    \"libgl1\" \\\n",
    "    \"libreoffice\" \\\n",
    "    \"fonts-noto-cjk\" \\\n",
    "    \"fonts-wqy-zenhei\" \\\n",
    "    \"fonts-wqy-microhei\" \\\n",
    "    \"ttf-mscorefonts-installer\" \\\n",
    "    \"fontconfig\" \\\n",
    "    \"libglib2.0-0\" \\\n",
    "    \"libxrender1\" \\\n",
    "    \"libsm6\" \\\n",
    "    \"libxext6\" \\\n",
    "    \"poppler-utils\" \n",
    "!rm -rf \"/var/lib/apt/lists/*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416f9c01",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%pip install  magic-pdf[full] -q\n",
    "%pip install huggingface_hub -q\n",
    "!wget https://github.com/opendatalab/MinerU/raw/master/scripts/download_models_hf.py -O download_models_hf.py\n",
    "!python download_models_hf.py\n",
    "%pip install litserve python-multipart -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5c30c2",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!rm -rf mineru-server\n",
    "!git clone https://github.com/bieno12/mineru-server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5d570d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/kaggle/working/mineru-server')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fb138d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import progress_monitor\n",
    "progress_monitor.patch_tqdm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb531dd-f8f1-4222-bbe7-4ab043181981",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from magic_pdf.data.data_reader_writer import FileBasedDataWriter, FileBasedDataReader\n",
    "from magic_pdf.data.dataset import PymuDocDataset\n",
    "from magic_pdf.model.doc_analyze_by_custom_model import doc_analyze\n",
    "from magic_pdf.config.enums import SupportedPdfParseMethod\n",
    "\n",
    "# args\n",
    "pdf_file_name = \"/kaggle/input/research-paper/13_Understanding LSTM Networks -- colahs blog.pdf\"  # replace with the real pdf path\n",
    "name_without_suff = os.path.basename(pdf_file_name).split(\".\")[0]\n",
    "\n",
    "# prepare env\n",
    "local_image_dir, local_md_dir = \"output/images\", \"output\"\n",
    "image_dir = str()\n",
    "\n",
    "os.makedirs(local_image_dir, exist_ok=True)\n",
    "\n",
    "image_writer, md_writer = FileBasedDataWriter(local_image_dir), FileBasedDataWriter(\n",
    "    local_md_dir\n",
    ")\n",
    "\n",
    "# read bytes\n",
    "reader1 = FileBasedDataReader(\"\")\n",
    "pdf_bytes = reader1.read(pdf_file_name)  # read the pdf content\n",
    "\n",
    "# proc\n",
    "## Create Dataset Instance\n",
    "ds = PymuDocDataset(pdf_bytes)\n",
    "\n",
    "## inference\n",
    "if ds.classify() == SupportedPdfParseMethod.OCR:\n",
    "    infer_result = ds.apply(doc_analyze, ocr=True)\n",
    "\n",
    "    ## pipeline\n",
    "    pipe_result = infer_result.pipe_ocr_mode(image_writer)\n",
    "\n",
    "else:\n",
    "    infer_result = doc_analyze(ds, ocr=False)\n",
    "\n",
    "    ## pipeline\n",
    "    pipe_result = infer_result.pipe_txt_mode(image_writer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02944d7e-1115-41be-ae38-708f03698264",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### draw model result on each page\n",
    "infer_result.draw_model(os.path.join(local_md_dir, f\"{name_without_suff}_model.pdf\"))\n",
    "\n",
    "### get model inference result\n",
    "model_inference_result = infer_result.get_infer_res()\n",
    "\n",
    "### draw layout result on each page\n",
    "pipe_result.draw_layout(os.path.join(local_md_dir, f\"{name_without_suff}_layout.pdf\"))\n",
    "\n",
    "### draw spans result on each page\n",
    "pipe_result.draw_span(os.path.join(local_md_dir, f\"{name_without_suff}_spans.pdf\"))\n",
    "\n",
    "### get markdown content\n",
    "md_content = pipe_result.get_markdown(image_dir)\n",
    "\n",
    "### dump markdown\n",
    "pipe_result.dump_md(md_writer, f\"{name_without_suff}.md\", image_dir)\n",
    "\n",
    "### get content list content\n",
    "content_list_content = pipe_result.get_content_list(image_dir)\n",
    "\n",
    "### dump content list\n",
    "pipe_result.dump_content_list(md_writer, f\"{name_without_suff}_content_list.json\", image_dir)\n",
    "\n",
    "### get middle json\n",
    "middle_json_content = pipe_result.get_middle_json()\n",
    "\n",
    "### dump middle json\n",
    "pipe_result.dump_middle_json(md_writer, f'{name_without_suff}_middle.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "470ba770",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T11:37:49.077370Z",
     "iopub.status.busy": "2025-06-10T11:37:49.077077Z",
     "iopub.status.idle": "2025-06-10T11:37:49.201187Z",
     "shell.execute_reply": "2025-06-10T11:37:49.200492Z",
     "shell.execute_reply.started": "2025-06-10T11:37:49.077346Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def override_config():\n",
    "    import json\n",
    "    config_path = '/root/magic-pdf.json'\n",
    "\n",
    "    # Load existing config\n",
    "    with open(config_path, 'r') as f:\n",
    "        config = json.load(f)\n",
    "\n",
    "    # Override device-mode to 'cuda'\n",
    "    config['device-mode'] = 'cuda'\n",
    "\n",
    "    # Save back to file\n",
    "    with open(config_path, 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "override_config()\n",
    "!cat  /root/magic-pdf.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b14ad5e3",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%writefile server.py\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/kaggle/working/mineru-server')\n",
    "\n",
    "import progress_monitor\n",
    "\n",
    "import litserve as ls\n",
    "import uvicorn\n",
    "from fastapi import Depends, HTTPException, UploadFile\n",
    "from fastapi.security import HTTPAuthorizationCredentials, HTTPBearer\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from typing import Any, Optional, List, Dict\n",
    "import base64, mimetypes\n",
    "\n",
    "progress_monitor.patch_tqdm()\n",
    "\n",
    "from magic_pdf.data.data_reader_writer import FileBasedDataWriter, FileBasedDataReader\n",
    "from magic_pdf.data.dataset import PymuDocDataset\n",
    "from magic_pdf.model.doc_analyze_by_custom_model import doc_analyze\n",
    "from magic_pdf.config.enums import SupportedPdfParseMethod\n",
    "from in_memory_writer import InMemoryDataWriter\n",
    "import json\n",
    "\n",
    "\n",
    "class ImageAPI(ls.LitAPI):\n",
    "    def setup(self, device):\n",
    "        self.poll_interval = 1.0\n",
    "        self.image_writer = InMemoryDataWriter()\n",
    "    def decode_request(self, request):\n",
    "        print(request['file'].filename)\n",
    "        pdf_bytes = request['file'].file.read()\n",
    "\n",
    "        ## Create Dataset Instance\n",
    "        ds = PymuDocDataset(pdf_bytes)\n",
    "        # Open and return the uploaded image file\n",
    "        args = {\n",
    "            'dataset': ds,\n",
    "            'start_page_id': request.get('start_page_id', 0),\n",
    "            'end_page_id': request.get('end_page_id', None),\n",
    "            'lang': request.get('lang', None),\n",
    "            'formula_enable': request.get('formula_enable', None),\n",
    "            'table_enable': request.get('table_enable', None),\n",
    "            'return_markdown': request.get('return_markdown', False)\n",
    "        }\n",
    "        return args\n",
    "\n",
    "    def predict(self, args):\n",
    "        self.image_writer.clear()\n",
    "        breturn_markdown = args.pop('return_markdown')\n",
    "        def infer():\n",
    "            ds = args.pop('dataset')\n",
    "            \n",
    "            if ds.classify() == SupportedPdfParseMethod.OCR:\n",
    "                infer_result = doc_analyze(ds, ocr=True)\n",
    "\n",
    "                ## pipeline\n",
    "                pipe_result = infer_result.pipe_ocr_mode(self.image_writer)\n",
    "\n",
    "            else:\n",
    "                infer_result = doc_analyze(ds, ocr=False)\n",
    "                pipe_result = infer_result.pipe_txt_mode(self.image_writer)\n",
    "            return pipe_result\n",
    "        update = {}\n",
    "        for update in progress_monitor.run_with_progress(infer, poll_interval=self.poll_interval):\n",
    "            if update['status'] != 'completed':\n",
    "                yield {\n",
    "                    'type': 'progress',\n",
    "                    'data': update,\n",
    "                }\n",
    "            else: break\n",
    "            \n",
    "        pipe_result = update.pop('result')\n",
    "        content_list = pipe_result.get_content_list(\"\")\n",
    "        self._encode_images(content_list)\n",
    "        \n",
    "        yield {\n",
    "             \"type\": \"progress\",\n",
    "             \"data\": update\n",
    "         }\n",
    "         \n",
    "        result = {\n",
    "            'type': 'result',\n",
    "            'data': {\n",
    "                \"content_list\": content_list,\n",
    "            },\n",
    "        }\n",
    "        \n",
    "        if breturn_markdown:\n",
    "            result['data']['markdown'] = pipe_result.get_markdown(\"\")\n",
    "            \n",
    "        yield result\n",
    "\n",
    "    def encode_response(self, chunks):\n",
    "        for chunk in chunks:\n",
    "            # Serialize in the most compact single-line form:\n",
    "            line = json.dumps(chunk, ensure_ascii=False, separators=(',', ':'))\n",
    "            # Then terminate with exactly one '\\n'\n",
    "            yield line + \"\\n\"\n",
    "\n",
    "    def authorize(self, auth: HTTPAuthorizationCredentials = Depends(HTTPBearer())):\n",
    "        if auth.scheme != \"Bearer\" or auth.credentials != \"secret_key\":\n",
    "            raise HTTPException(status_code=401, detail=\"Bad token\")\n",
    "        \n",
    "    def _encode_images(self, content_list: List[Dict]) -> None:\n",
    "        \"\"\"\n",
    "        Enhanced version with better error handling and MIME type detection.\n",
    "        \n",
    "        Args:\n",
    "            content_list: List of content items, some may have type \"image\"\n",
    "        \"\"\"\n",
    "        \n",
    "        for item in content_list:\n",
    "            if item.get('type') in ['image', 'table']:\n",
    "                image_path = item.pop('img_path')\n",
    "                if image_path.startswith('/'):\n",
    "                    image_path = image_path[1:]\n",
    "                \n",
    "                if image_path:\n",
    "                    try:\n",
    "                        # Read the image data from the in-memory writer\n",
    "                        image_bytes = self.image_writer.read(image_path)\n",
    "                        \n",
    "                        if image_bytes:\n",
    "                            # Encode to base64\n",
    "                            base64_data = base64.b64encode(image_bytes).decode('utf-8')\n",
    "                            \n",
    "                            # Optionally detect MIME type and create data URL\n",
    "                            mime_type, _ = mimetypes.guess_type(image_path)\n",
    "                            if mime_type and mime_type.startswith('image/'):\n",
    "                                # Create a data URL format: data:image/png;base64,<base64_data>\n",
    "                                item['img_url'] = f\"data:{mime_type};base64,{base64_data}\"\n",
    "                            \n",
    "                        else:\n",
    "                            print(f\"Warning: Image data not found for path: {image_path}\")\n",
    "                            item['img_url'] = None\n",
    "                            \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error encoding image {image_path}: {str(e)}\")\n",
    "                        item['img_url'] = None\n",
    "                else:\n",
    "                    print(f\"Warning: No image path found in item: {item}\")\n",
    "                    item['img_url'] = None\n",
    "                    \n",
    "if __name__ == '__main__':\n",
    "    api = ImageAPI(stream=True)\n",
    "    server = ls.LitServer(api)\n",
    "    server.run(\"0.0.0.0\", 8000, reload=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7b64d02",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!python server.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "304129ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from magic_pdf.data.data_reader_writer import FileBasedDataWriter, FileBasedDataReader, DataWriter\n",
    "from magic_pdf.data.dataset import PymuDocDataset\n",
    "from magic_pdf.model.doc_analyze_by_custom_model import doc_analyze\n",
    "from magic_pdf.config.enums import SupportedPdfParseMethod\n",
    "import mimetypes\n",
    "import base64\n",
    "from typing import Dict, Optional, List\n",
    "from in_memory_writer import InMemoryDataWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aa6841",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ImageAPI:\n",
    "    def setup(self, device):\n",
    "        self.poll_interval = 1.0\n",
    "        self.image_writer = InMemoryDataWriter()\n",
    "    def decode_request(self, request):\n",
    "        print(request['file'].filename)\n",
    "        pdf_bytes = request['file'].file.read()\n",
    "        # proc\n",
    "\n",
    "        ## Create Dataset Instance\n",
    "        ds = PymuDocDataset(pdf_bytes)\n",
    "        # Open and return the uploaded image file\n",
    "        args = {\n",
    "            'dataset': ds,\n",
    "            'start_page_id': request.get('start_page_id', 0),\n",
    "            'end_page_id': request.get('end_page_id', None),\n",
    "            'lang': request.get('lang', None),\n",
    "            'formula_enable': request.get('formula_enable', None),\n",
    "            'table_enable': request.get('table_enable', None),\n",
    "            'return_markdown': request.get('return_markdown', False)\n",
    "        }\n",
    "        return args\n",
    "\n",
    "    def predict(self, args):\n",
    "        self.image_writer.clear()\n",
    "        breturn_markdown = args.pop('return_markdown')\n",
    "        def infer():\n",
    "            ds = args.pop('dataset')\n",
    "            \n",
    "            if ds.classify() == SupportedPdfParseMethod.OCR:\n",
    "                infer_result = doc_analyze(ds, ocr=True)\n",
    "\n",
    "                ## pipeline\n",
    "                pipe_result = infer_result.pipe_ocr_mode(self.image_writer)\n",
    "\n",
    "            else:\n",
    "                infer_result = doc_analyze(ds, ocr=False)\n",
    "                pipe_result = infer_result.pipe_txt_mode(self.image_writer)\n",
    "            return pipe_result\n",
    "        update = {}\n",
    "        for update in progress_monitor.run_with_progress(infer, poll_interval=self.poll_interval):\n",
    "            if update['status'] != 'completed':\n",
    "                yield {\n",
    "                    'type': 'progress',\n",
    "                    'data': update,\n",
    "                }\n",
    "            else: break\n",
    "            \n",
    "        pipe_result = update.pop('result')\n",
    "        content_list = pipe_result.get_content_list(\"\")\n",
    "        self._encode_images(content_list)\n",
    "        \n",
    "        yield {\n",
    "             \"type\": \"progress\",\n",
    "             \"data\": update\n",
    "         }\n",
    "         \n",
    "        result = {\n",
    "            'type': 'result',\n",
    "            'data': {\n",
    "                \"content_list\": content_list,\n",
    "            },\n",
    "        }\n",
    "        \n",
    "        if breturn_markdown:\n",
    "            result['markdown'] = pipe_result.get_markdown(\"\")\n",
    "            \n",
    "        yield result\n",
    "\n",
    "    def _encode_images(self, content_list: List[Dict]) -> None:\n",
    "        \"\"\"\n",
    "        Enhanced version with better error handling and MIME type detection.\n",
    "        \n",
    "        Args:\n",
    "            content_list: List of content items, some may have type \"image\"\n",
    "        \"\"\"\n",
    "        \n",
    "        for item in content_list:\n",
    "            if item.get('type') in ['image', 'table']:\n",
    "                image_path = item.pop('img_path')\n",
    "                if image_path.startswith('/'):\n",
    "                    image_path = image_path[1:]\n",
    "                \n",
    "                if image_path:\n",
    "                    try:\n",
    "                        # Read the image data from the in-memory writer\n",
    "                        image_bytes = self.image_writer.read(image_path)\n",
    "                        \n",
    "                        if image_bytes:\n",
    "                            # Encode to base64\n",
    "                            base64_data = base64.b64encode(image_bytes).decode('utf-8')\n",
    "                            \n",
    "                            # Optionally detect MIME type and create data URL\n",
    "                            mime_type, _ = mimetypes.guess_type(image_path)\n",
    "                            if mime_type and mime_type.startswith('image/'):\n",
    "                                # Create a data URL format: data:image/png;base64,<base64_data>\n",
    "                                item['img_url'] = f\"data:{mime_type};base64,{base64_data}\"\n",
    "                            \n",
    "                        else:\n",
    "                            print(f\"Warning: Image data not found for path: {image_path}\")\n",
    "                            item['img_url'] = None\n",
    "                            \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error encoding image {image_path}: {str(e)}\")\n",
    "                        item['img_url'] = None\n",
    "                else:\n",
    "                    print(f\"Warning: No image path found in item: {item}\")\n",
    "                    item['img_url'] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59532b1",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pdf_file = '/kaggle/input/research-paper/12_Convo.pdf'\n",
    "with open(pdf_file, 'rb') as f:\n",
    "    pdf_bytes = f.read()\n",
    "ds = PymuDocDataset(pdf_bytes)\n",
    "# Open and return the uploaded image file\n",
    "args = {\n",
    "    'dataset': ds,\n",
    "    'start_page_id': 0,\n",
    "    'end_page_id': None,\n",
    "    'lang': None,\n",
    "    'formula_enable': None,\n",
    "    'table_enable': None,\n",
    "}\n",
    "\n",
    "api = ImageAPI()\n",
    "api.setup('cuda')\n",
    "for chunk in api.predict(args):\n",
    "    print(chunk)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 951471,
     "sourceId": 1633729,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
